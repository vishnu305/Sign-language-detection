{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eddcd71",
   "metadata": {},
   "source": [
    "# Import and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eac970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d8eb16",
   "metadata": {},
   "source": [
    "# Key points using Media pipe holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0611f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic #holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils #drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fc2d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image,model):\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB) #color conversion bgr to rgb\n",
    "    image.flags.writeable=False  #image is no longer writeable\n",
    "    results=model.process(image)  #make prediction\n",
    "    image.flags.writeable=True  #image is now writable\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_RGB2BGR) #color conversion rgb to bgr\n",
    "    return image,results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b10de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image,results):\n",
    "    mp_drawing.draw_landmarks(image,results.face_landmarks,mp_holistic.FACEMESH_CONTOURS)\n",
    "    mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e71d9c84",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({(0, 1),\n",
       "           (0, 4),\n",
       "           (1, 2),\n",
       "           (2, 3),\n",
       "           (3, 7),\n",
       "           (4, 5),\n",
       "           (5, 6),\n",
       "           (6, 8),\n",
       "           (9, 10),\n",
       "           (11, 12),\n",
       "           (11, 13),\n",
       "           (11, 23),\n",
       "           (12, 14),\n",
       "           (12, 24),\n",
       "           (13, 15),\n",
       "           (14, 16),\n",
       "           (15, 17),\n",
       "           (15, 19),\n",
       "           (15, 21),\n",
       "           (16, 18),\n",
       "           (16, 20),\n",
       "           (16, 22),\n",
       "           (17, 19),\n",
       "           (18, 20),\n",
       "           (23, 24),\n",
       "           (23, 25),\n",
       "           (24, 26),\n",
       "           (25, 27),\n",
       "           (26, 28),\n",
       "           (27, 29),\n",
       "           (27, 31),\n",
       "           (28, 30),\n",
       "           (28, 32),\n",
       "           (29, 31),\n",
       "           (30, 32)})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_holistic.POSE_CONNECTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "318d8e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing.draw_landmarks??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6325e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_styled_landmarks(image, results):\n",
    "    # Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             ) \n",
    "    # Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff7f1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image,results = mediapipe_detection(frame,holistic)\n",
    "        \n",
    "        #draw landmarks\n",
    "        draw_landmarks(image,results)\n",
    "        draw_styled_landmarks(image,results)\n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed',image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660d02f4",
   "metadata": {},
   "source": [
    "# Extract key point values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "604c772c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.62738407,  0.65827847, -0.9792062 ,  0.98509121],\n",
       "       [ 0.62240237,  0.60336536, -1.02160907,  0.98840696],\n",
       "       [ 0.62652594,  0.60119128, -1.02091527,  0.99005473],\n",
       "       [ 0.63028419,  0.59907144, -1.02030289,  0.99067456],\n",
       "       [ 0.59998637,  0.60407436, -1.07833529,  0.9834584 ],\n",
       "       [ 0.58819985,  0.60198563, -1.0781424 ,  0.98056513],\n",
       "       [ 0.57521093,  0.59986883, -1.07753515,  0.97744304],\n",
       "       [ 0.61308789,  0.58903968, -0.87197101,  0.99301785],\n",
       "       [ 0.52874792,  0.59178257, -1.1000551 ,  0.9827826 ],\n",
       "       [ 0.6371733 ,  0.68621284, -0.87402999,  0.98673302],\n",
       "       [ 0.61450815,  0.68557733, -0.95854539,  0.98036945],\n",
       "       [ 0.61774516,  0.74592894, -0.57945627,  0.95677769],\n",
       "       [ 0.40440011,  0.73464864, -0.92535782,  0.93491191],\n",
       "       [ 0.73955256,  0.84161478, -0.3076511 ,  0.50960165],\n",
       "       [ 0.49151525,  0.72100747, -0.76492661,  0.50936347],\n",
       "       [ 0.76415503,  0.85695589, -0.21669266,  0.22521958],\n",
       "       [ 0.64134109,  0.65858418, -0.39007279,  0.25301343],\n",
       "       [ 0.77708471,  0.8696444 , -0.22566816,  0.23141453],\n",
       "       [ 0.68180215,  0.65952575, -0.41554752,  0.23022819],\n",
       "       [ 0.74414927,  0.84038162, -0.31445137,  0.29779431],\n",
       "       [ 0.67774439,  0.64062065, -0.40959445,  0.28029555],\n",
       "       [ 0.7311995 ,  0.83557254, -0.24925745,  0.29773977],\n",
       "       [ 0.66702133,  0.6434958 , -0.38158375,  0.29132268],\n",
       "       [ 0.54675257,  1.4257915 ,  0.0196513 ,  0.02395872],\n",
       "       [ 0.45905489,  1.5100913 , -0.01879426,  0.01330681],\n",
       "       [ 0.68703049,  0.83427197,  0.22417638,  0.0603963 ],\n",
       "       [ 0.51828045,  1.03341877,  0.2983911 ,  0.02527273],\n",
       "       [ 0.63573301,  0.85724109,  1.02731407,  0.03768451],\n",
       "       [ 0.64077759,  0.87446606,  0.92065609,  0.02889036],\n",
       "       [ 0.59151614,  0.87406707,  1.09755635,  0.03079574],\n",
       "       [ 0.63548112,  0.86168468,  1.00835323,  0.02045896],\n",
       "       [ 0.68058664,  0.84500086,  0.86768401,  0.05024311],\n",
       "       [ 0.68445235,  0.76740623,  0.79971433,  0.04756748]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose=[]\n",
    "for res in results.pose_landmarks.landmark:\n",
    "    test = np.array([res.x,res.y,res.z,res.visibility])\n",
    "    pose.append(test)\n",
    "pose=np.array(pose)\n",
    "pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ede8fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(132)\n",
    "face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(1404)\n",
    "lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8fe2e995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87b784a7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.62738407,  0.65827847, -0.9792062 ,  0.98509121,  0.62240237,\n",
       "        0.60336536, -1.02160907,  0.98840696,  0.62652594,  0.60119128,\n",
       "       -1.02091527,  0.99005473,  0.63028419,  0.59907144, -1.02030289,\n",
       "        0.99067456,  0.59998637,  0.60407436, -1.07833529,  0.9834584 ,\n",
       "        0.58819985,  0.60198563, -1.0781424 ,  0.98056513,  0.57521093,\n",
       "        0.59986883, -1.07753515,  0.97744304,  0.61308789,  0.58903968,\n",
       "       -0.87197101,  0.99301785,  0.52874792,  0.59178257, -1.1000551 ,\n",
       "        0.9827826 ,  0.6371733 ,  0.68621284, -0.87402999,  0.98673302,\n",
       "        0.61450815,  0.68557733, -0.95854539,  0.98036945,  0.61774516,\n",
       "        0.74592894, -0.57945627,  0.95677769,  0.40440011,  0.73464864,\n",
       "       -0.92535782,  0.93491191,  0.73955256,  0.84161478, -0.3076511 ,\n",
       "        0.50960165,  0.49151525,  0.72100747, -0.76492661,  0.50936347,\n",
       "        0.76415503,  0.85695589, -0.21669266,  0.22521958,  0.64134109,\n",
       "        0.65858418, -0.39007279,  0.25301343,  0.77708471,  0.8696444 ,\n",
       "       -0.22566816,  0.23141453,  0.68180215,  0.65952575, -0.41554752,\n",
       "        0.23022819,  0.74414927,  0.84038162, -0.31445137,  0.29779431,\n",
       "        0.67774439,  0.64062065, -0.40959445,  0.28029555,  0.7311995 ,\n",
       "        0.83557254, -0.24925745,  0.29773977,  0.66702133,  0.6434958 ,\n",
       "       -0.38158375,  0.29132268,  0.54675257,  1.4257915 ,  0.0196513 ,\n",
       "        0.02395872,  0.45905489,  1.5100913 , -0.01879426,  0.01330681,\n",
       "        0.68703049,  0.83427197,  0.22417638,  0.0603963 ,  0.51828045,\n",
       "        1.03341877,  0.2983911 ,  0.02527273,  0.63573301,  0.85724109,\n",
       "        1.02731407,  0.03768451,  0.64077759,  0.87446606,  0.92065609,\n",
       "        0.02889036,  0.59151614,  0.87406707,  1.09755635,  0.03079574,\n",
       "        0.63548112,  0.86168468,  1.00835323,  0.02045896,  0.68058664,\n",
       "        0.84500086,  0.86768401,  0.05024311,  0.68445235,  0.76740623,\n",
       "        0.79971433,  0.04756748])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33263592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ea0d0398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1662,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_keypoints(results).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e89b917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1662"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "468*3+33*4+21*3+21*3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092799d",
   "metadata": {},
   "source": [
    "# setup folders for data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed71d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('MP_Data') \n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = np.array(['hello', 'thanks', 'iloveyou'])\n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 30\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30\n",
    "\n",
    "# Folder start\n",
    "start_folder = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8cb0ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hello \n",
    "##0\n",
    "##1\n",
    "#...\n",
    "##29\n",
    "\n",
    "#thanks\n",
    "\n",
    "#I love you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "713d9d20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'actions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18560/361714751.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#     dirmax = np.max(np.array(os.listdir(os.path.join(DATA_PATH, action))).astype(int))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msequence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'actions' is not defined"
     ]
    }
   ],
   "source": [
    "for action in actions: \n",
    "#     dirmax = np.max(np.array(os.listdir(os.path.join(DATA_PATH, action))).astype(int))\n",
    "    for sequence in range(no_sequences):\n",
    "        try: \n",
    "            os.makedirs(os.path.join(DATA_PATH, action, str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc349224",
   "metadata": {},
   "source": [
    "# Collect keypoint values for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b631c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    for action in actions:\n",
    "        for sequence in range(no_sequences):\n",
    "            for frame_num in range(sequence_length):\n",
    "                \n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                #make detections\n",
    "                image,results = mediapipe_detection(frame,holistic)\n",
    "\n",
    "                #draw landmarks\n",
    "                draw_landmarks(image,results)\n",
    "                draw_styled_landmarks(image,results)\n",
    "                \n",
    "                if frame_num == 0:\n",
    "                    cv2.putText(image,'STARTING COLLECTION',(120,200),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),4,cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(500)\n",
    "                else: \n",
    "                    cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, sequence), (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                \n",
    "                # NEW Export keypoints\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
    "                np.save(npy_path, keypoints)\n",
    "                #show to screen\n",
    "                cv2.imshow('OpenCV Feed',image)\n",
    "                \n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3958c4d",
   "metadata": {},
   "source": [
    "# Preprocess Data and create labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7a30ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d458e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f9b206f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 0, 'thanks': 1, 'iloveyou': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d17f6de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in np.array(os.listdir(os.path.join(DATA_PATH, action))).astype(int):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1629c7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 30, 1662)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd54f7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "928a4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "202dd27a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(labels).astype(int)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d9a6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de71c668",
   "metadata": {},
   "source": [
    "# Build and train LSTM Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f945d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a26e1b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51a556ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,1662)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9df417ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "752cae16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "3/3 [==============================] - 6s 530ms/step - loss: 4.1600 - categorical_accuracy: 0.3529\n",
      "Epoch 2/2000\n",
      "3/3 [==============================] - 2s 539ms/step - loss: 1.2193 - categorical_accuracy: 0.2706\n",
      "Epoch 3/2000\n",
      "3/3 [==============================] - 2s 512ms/step - loss: 1.1752 - categorical_accuracy: 0.2706\n",
      "Epoch 4/2000\n",
      "3/3 [==============================] - 2s 531ms/step - loss: 1.0856 - categorical_accuracy: 0.4353\n",
      "Epoch 5/2000\n",
      "3/3 [==============================] - 2s 525ms/step - loss: 1.2912 - categorical_accuracy: 0.2824\n",
      "Epoch 6/2000\n",
      "3/3 [==============================] - 2s 544ms/step - loss: 1.3025 - categorical_accuracy: 0.4000\n",
      "Epoch 7/2000\n",
      "3/3 [==============================] - 2s 530ms/step - loss: 1.1050 - categorical_accuracy: 0.4000\n",
      "Epoch 8/2000\n",
      "3/3 [==============================] - 2s 526ms/step - loss: 0.9737 - categorical_accuracy: 0.4941\n",
      "Epoch 9/2000\n",
      "3/3 [==============================] - 2s 521ms/step - loss: 0.8417 - categorical_accuracy: 0.6353\n",
      "Epoch 10/2000\n",
      "3/3 [==============================] - 2s 574ms/step - loss: 0.6845 - categorical_accuracy: 0.5882\n",
      "Epoch 11/2000\n",
      "3/3 [==============================] - 2s 516ms/step - loss: 2.4133 - categorical_accuracy: 0.5176\n",
      "Epoch 12/2000\n",
      "3/3 [==============================] - 2s 531ms/step - loss: 0.8418 - categorical_accuracy: 0.5882\n",
      "Epoch 13/2000\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 0.6927 - categorical_accuracy: 0.6471\n",
      "Epoch 14/2000\n",
      "3/3 [==============================] - 2s 676ms/step - loss: 0.7047 - categorical_accuracy: 0.6471\n",
      "Epoch 15/2000\n",
      "3/3 [==============================] - 2s 662ms/step - loss: 0.6290 - categorical_accuracy: 0.6235\n",
      "Epoch 16/2000\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 0.5690 - categorical_accuracy: 0.7059\n",
      "Epoch 17/2000\n",
      "3/3 [==============================] - 2s 533ms/step - loss: 0.5323 - categorical_accuracy: 0.6353\n",
      "Epoch 18/2000\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 0.4911 - categorical_accuracy: 0.7529\n",
      "Epoch 19/2000\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 0.4969 - categorical_accuracy: 0.6941\n",
      "Epoch 20/2000\n",
      "3/3 [==============================] - 2s 650ms/step - loss: 0.5306 - categorical_accuracy: 0.6824\n",
      "Epoch 21/2000\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 0.4523 - categorical_accuracy: 0.7294\n",
      "Epoch 22/2000\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 0.4490 - categorical_accuracy: 0.6941\n",
      "Epoch 23/2000\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 0.4258 - categorical_accuracy: 0.7059\n",
      "Epoch 24/2000\n",
      "3/3 [==============================] - 2s 555ms/step - loss: 0.4237 - categorical_accuracy: 0.7647\n",
      "Epoch 25/2000\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 0.4234 - categorical_accuracy: 0.7647\n",
      "Epoch 26/2000\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 0.5144 - categorical_accuracy: 0.7176\n",
      "Epoch 27/2000\n",
      "3/3 [==============================] - 2s 576ms/step - loss: 0.6798 - categorical_accuracy: 0.6353\n",
      "Epoch 28/2000\n",
      "3/3 [==============================] - 2s 583ms/step - loss: 0.5700 - categorical_accuracy: 0.6118\n",
      "Epoch 29/2000\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 0.5277 - categorical_accuracy: 0.6706\n",
      "Epoch 30/2000\n",
      "3/3 [==============================] - 2s 590ms/step - loss: 0.5722 - categorical_accuracy: 0.6706\n",
      "Epoch 31/2000\n",
      "3/3 [==============================] - 2s 586ms/step - loss: 0.5107 - categorical_accuracy: 0.6706\n",
      "Epoch 32/2000\n",
      "3/3 [==============================] - 2s 585ms/step - loss: 0.5253 - categorical_accuracy: 0.6824\n",
      "Epoch 33/2000\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 0.5101 - categorical_accuracy: 0.6824\n",
      "Epoch 34/2000\n",
      "3/3 [==============================] - 2s 666ms/step - loss: 0.4684 - categorical_accuracy: 0.6941\n",
      "Epoch 35/2000\n",
      "3/3 [==============================] - 2s 648ms/step - loss: 0.4706 - categorical_accuracy: 0.6824\n",
      "Epoch 36/2000\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 0.4632 - categorical_accuracy: 0.6824\n",
      "Epoch 37/2000\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 0.4450 - categorical_accuracy: 0.7412\n",
      "Epoch 38/2000\n",
      "3/3 [==============================] - 2s 642ms/step - loss: 0.4431 - categorical_accuracy: 0.6824\n",
      "Epoch 39/2000\n",
      "3/3 [==============================] - 2s 584ms/step - loss: 0.4372 - categorical_accuracy: 0.7059\n",
      "Epoch 40/2000\n",
      "3/3 [==============================] - 2s 568ms/step - loss: 0.4616 - categorical_accuracy: 0.7059\n",
      "Epoch 41/2000\n",
      "3/3 [==============================] - 2s 581ms/step - loss: 0.4315 - categorical_accuracy: 0.7294\n",
      "Epoch 42/2000\n",
      "3/3 [==============================] - 2s 675ms/step - loss: 0.4012 - categorical_accuracy: 0.8000\n",
      "Epoch 43/2000\n",
      "3/3 [==============================] - 2s 653ms/step - loss: 0.4667 - categorical_accuracy: 0.7765\n",
      "Epoch 44/2000\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 0.4441 - categorical_accuracy: 0.7176\n",
      "Epoch 45/2000\n",
      "3/3 [==============================] - 2s 572ms/step - loss: 0.4535 - categorical_accuracy: 0.7176\n",
      "Epoch 46/2000\n",
      "3/3 [==============================] - 2s 618ms/step - loss: 0.4439 - categorical_accuracy: 0.7176\n",
      "Epoch 47/2000\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 0.4068 - categorical_accuracy: 0.7294\n",
      "Epoch 48/2000\n",
      "3/3 [==============================] - 2s 551ms/step - loss: 0.4341 - categorical_accuracy: 0.7176\n",
      "Epoch 49/2000\n",
      "3/3 [==============================] - 2s 556ms/step - loss: 0.4067 - categorical_accuracy: 0.7647\n",
      "Epoch 50/2000\n",
      "3/3 [==============================] - 2s 578ms/step - loss: 0.3814 - categorical_accuracy: 0.8118\n",
      "Epoch 51/2000\n",
      "3/3 [==============================] - 2s 586ms/step - loss: 0.4309 - categorical_accuracy: 0.7176\n",
      "Epoch 52/2000\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 0.4377 - categorical_accuracy: 0.7059\n",
      "Epoch 53/2000\n",
      "3/3 [==============================] - 2s 572ms/step - loss: 0.4481 - categorical_accuracy: 0.7412\n",
      "Epoch 54/2000\n",
      "3/3 [==============================] - 2s 549ms/step - loss: 0.3847 - categorical_accuracy: 0.8000\n",
      "Epoch 55/2000\n",
      "3/3 [==============================] - 2s 522ms/step - loss: 0.4319 - categorical_accuracy: 0.7176\n",
      "Epoch 56/2000\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 0.3911 - categorical_accuracy: 0.8235\n",
      "Epoch 57/2000\n",
      "3/3 [==============================] - 2s 625ms/step - loss: 0.4083 - categorical_accuracy: 0.7294\n",
      "Epoch 58/2000\n",
      "3/3 [==============================] - 2s 558ms/step - loss: 0.4099 - categorical_accuracy: 0.7529\n",
      "Epoch 59/2000\n",
      "3/3 [==============================] - 2s 581ms/step - loss: 0.3476 - categorical_accuracy: 0.8118\n",
      "Epoch 60/2000\n",
      "3/3 [==============================] - 2s 540ms/step - loss: 1.1129 - categorical_accuracy: 0.5412\n",
      "Epoch 61/2000\n",
      "3/3 [==============================] - 2s 587ms/step - loss: 0.5532 - categorical_accuracy: 0.6824\n",
      "Epoch 62/2000\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 0.6576 - categorical_accuracy: 0.6706\n",
      "Epoch 63/2000\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 0.6382 - categorical_accuracy: 0.6706\n",
      "Epoch 64/2000\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 0.5657 - categorical_accuracy: 0.6588\n",
      "Epoch 65/2000\n",
      "3/3 [==============================] - 2s 640ms/step - loss: 0.5192 - categorical_accuracy: 0.6353\n",
      "Epoch 66/2000\n",
      "3/3 [==============================] - 2s 630ms/step - loss: 0.4649 - categorical_accuracy: 0.6706\n",
      "Epoch 67/2000\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 0.4498 - categorical_accuracy: 0.8235\n",
      "Epoch 68/2000\n",
      "3/3 [==============================] - 2s 550ms/step - loss: 0.5603 - categorical_accuracy: 0.7176\n",
      "Epoch 69/2000\n",
      "3/3 [==============================] - 2s 538ms/step - loss: 1.0591 - categorical_accuracy: 0.5647\n",
      "Epoch 70/2000\n",
      "3/3 [==============================] - 2s 519ms/step - loss: 1.3920 - categorical_accuracy: 0.4235\n",
      "Epoch 71/2000\n",
      "3/3 [==============================] - 2s 569ms/step - loss: 0.9052 - categorical_accuracy: 0.4353\n",
      "Epoch 72/2000\n",
      "3/3 [==============================] - 2s 567ms/step - loss: 0.8985 - categorical_accuracy: 0.4941\n",
      "Epoch 73/2000\n",
      "3/3 [==============================] - 2s 517ms/step - loss: 2.1876 - categorical_accuracy: 0.3294\n",
      "Epoch 74/2000\n",
      "3/3 [==============================] - 2s 520ms/step - loss: 0.9841 - categorical_accuracy: 0.3294\n",
      "Epoch 75/2000\n",
      "3/3 [==============================] - 2s 542ms/step - loss: 0.9770 - categorical_accuracy: 0.3294\n",
      "Epoch 76/2000\n",
      "3/3 [==============================] - 2s 523ms/step - loss: 0.9582 - categorical_accuracy: 0.3294\n",
      "Epoch 77/2000\n",
      "3/3 [==============================] - 2s 523ms/step - loss: 0.8463 - categorical_accuracy: 0.5059\n",
      "Epoch 78/2000\n",
      "3/3 [==============================] - 2s 523ms/step - loss: 0.7440 - categorical_accuracy: 0.7294\n",
      "Epoch 79/2000\n",
      "3/3 [==============================] - 2s 541ms/step - loss: 0.6833 - categorical_accuracy: 0.6824\n",
      "Epoch 80/2000\n",
      "3/3 [==============================] - 2s 520ms/step - loss: 10.7114 - categorical_accuracy: 0.5647\n",
      "Epoch 81/2000\n",
      "3/3 [==============================] - 2s 518ms/step - loss: 3.8764 - categorical_accuracy: 0.2471\n",
      "Epoch 82/2000\n",
      "3/3 [==============================] - 2s 532ms/step - loss: 1.0102 - categorical_accuracy: 0.4118\n",
      "Epoch 83/2000\n",
      "3/3 [==============================] - 2s 535ms/step - loss: 1.0565 - categorical_accuracy: 0.3294\n",
      "Epoch 84/2000\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 0.9775 - categorical_accuracy: 0.4235\n",
      "Epoch 85/2000\n",
      "3/3 [==============================] - 2s 527ms/step - loss: 0.9717 - categorical_accuracy: 0.4353\n",
      "Epoch 86/2000\n",
      "3/3 [==============================] - 2s 540ms/step - loss: 0.9632 - categorical_accuracy: 0.4235\n",
      "Epoch 87/2000\n",
      "3/3 [==============================] - 2s 535ms/step - loss: 0.9495 - categorical_accuracy: 0.4235\n",
      "Epoch 88/2000\n",
      "3/3 [==============================] - 2s 526ms/step - loss: 0.9240 - categorical_accuracy: 0.3765\n",
      "Epoch 89/2000\n",
      "3/3 [==============================] - 2s 537ms/step - loss: 0.8726 - categorical_accuracy: 0.5294\n",
      "Epoch 90/2000\n",
      "3/3 [==============================] - 2s 536ms/step - loss: 0.7914 - categorical_accuracy: 0.5765\n",
      "Epoch 91/2000\n",
      "3/3 [==============================] - 2s 536ms/step - loss: 0.6714 - categorical_accuracy: 0.6471\n",
      "Epoch 92/2000\n",
      "3/3 [==============================] - 2s 538ms/step - loss: 0.5273 - categorical_accuracy: 0.6353\n",
      "Epoch 93/2000\n",
      "3/3 [==============================] - 2s 520ms/step - loss: 9.4850 - categorical_accuracy: 0.5882\n",
      "Epoch 94/2000\n",
      "3/3 [==============================] - 2s 537ms/step - loss: 0.5643 - categorical_accuracy: 0.6706\n",
      "Epoch 95/2000\n",
      "3/3 [==============================] - 2s 532ms/step - loss: 0.6071 - categorical_accuracy: 0.6588\n",
      "Epoch 96/2000\n",
      "3/3 [==============================] - 2s 535ms/step - loss: 0.5500 - categorical_accuracy: 0.6824\n",
      "Epoch 97/2000\n",
      "3/3 [==============================] - 2s 528ms/step - loss: 0.4960 - categorical_accuracy: 0.6824\n",
      "Epoch 98/2000\n",
      "3/3 [==============================] - 2s 562ms/step - loss: 0.4847 - categorical_accuracy: 0.6000\n",
      "Epoch 99/2000\n",
      "3/3 [==============================] - 2s 543ms/step - loss: 0.6708 - categorical_accuracy: 0.6588\n",
      "Epoch 100/2000\n",
      "3/3 [==============================] - 2s 574ms/step - loss: 1.3047 - categorical_accuracy: 0.5529\n",
      "Epoch 101/2000\n",
      "3/3 [==============================] - 2s 543ms/step - loss: 1.8916 - categorical_accuracy: 0.4941\n",
      "Epoch 102/2000\n",
      "3/3 [==============================] - 2s 541ms/step - loss: 0.8554 - categorical_accuracy: 0.4706\n",
      "Epoch 103/2000\n",
      "3/3 [==============================] - 2s 543ms/step - loss: 1.1481 - categorical_accuracy: 0.4588\n",
      "Epoch 104/2000\n",
      "3/3 [==============================] - 2s 537ms/step - loss: 0.9382 - categorical_accuracy: 0.3882\n",
      "Epoch 105/2000\n",
      "3/3 [==============================] - 2s 530ms/step - loss: 0.9285 - categorical_accuracy: 0.4353\n",
      "Epoch 106/2000\n",
      "3/3 [==============================] - 2s 546ms/step - loss: 0.9333 - categorical_accuracy: 0.4471\n",
      "Epoch 107/2000\n",
      "3/3 [==============================] - 2s 569ms/step - loss: 0.9060 - categorical_accuracy: 0.4353\n",
      "Epoch 108/2000\n",
      "3/3 [==============================] - 2s 522ms/step - loss: 0.8802 - categorical_accuracy: 0.4353\n",
      "Epoch 109/2000\n",
      "3/3 [==============================] - 2s 545ms/step - loss: 0.8343 - categorical_accuracy: 0.4471\n",
      "Epoch 110/2000\n",
      "3/3 [==============================] - 2s 515ms/step - loss: 0.7765 - categorical_accuracy: 0.4353\n",
      "Epoch 111/2000\n",
      "3/3 [==============================] - 2s 530ms/step - loss: 0.7420 - categorical_accuracy: 0.4706\n",
      "Epoch 112/2000\n",
      "3/3 [==============================] - 2s 522ms/step - loss: 0.7333 - categorical_accuracy: 0.4824\n",
      "Epoch 113/2000\n",
      "3/3 [==============================] - 2s 540ms/step - loss: 0.6852 - categorical_accuracy: 0.6353\n",
      "Epoch 114/2000\n",
      "3/3 [==============================] - 2s 533ms/step - loss: 0.6848 - categorical_accuracy: 0.6471\n",
      "Epoch 115/2000\n",
      "3/3 [==============================] - 2s 517ms/step - loss: 0.6475 - categorical_accuracy: 0.6471\n",
      "Epoch 116/2000\n",
      "3/3 [==============================] - 2s 527ms/step - loss: 0.6126 - categorical_accuracy: 0.7176\n",
      "Epoch 117/2000\n",
      "3/3 [==============================] - 2s 528ms/step - loss: 0.5942 - categorical_accuracy: 0.7294\n",
      "Epoch 118/2000\n",
      "3/3 [==============================] - 2s 524ms/step - loss: 0.9200 - categorical_accuracy: 0.5765\n",
      "Epoch 119/2000\n",
      "3/3 [==============================] - 2s 526ms/step - loss: 0.6505 - categorical_accuracy: 0.6353\n",
      "Epoch 120/2000\n",
      "3/3 [==============================] - 2s 542ms/step - loss: 0.6247 - categorical_accuracy: 0.6000\n",
      "Epoch 121/2000\n",
      "3/3 [==============================] - 2s 528ms/step - loss: 0.6264 - categorical_accuracy: 0.6000\n",
      "Epoch 122/2000\n",
      "3/3 [==============================] - 2s 522ms/step - loss: 0.5774 - categorical_accuracy: 0.6000\n",
      "Epoch 123/2000\n",
      "3/3 [==============================] - 2s 519ms/step - loss: 0.5700 - categorical_accuracy: 0.6588\n",
      "Epoch 124/2000\n",
      "3/3 [==============================] - 2s 539ms/step - loss: 0.5244 - categorical_accuracy: 0.6824\n",
      "Epoch 125/2000\n",
      "3/3 [==============================] - 2s 533ms/step - loss: 0.4980 - categorical_accuracy: 0.6824\n",
      "Epoch 126/2000\n",
      "3/3 [==============================] - 2s 519ms/step - loss: 0.4786 - categorical_accuracy: 0.6824\n",
      "Epoch 127/2000\n",
      "3/3 [==============================] - 2s 527ms/step - loss: 0.4594 - categorical_accuracy: 0.6824\n",
      "Epoch 128/2000\n",
      "3/3 [==============================] - 2s 537ms/step - loss: 0.4403 - categorical_accuracy: 0.6941\n",
      "Epoch 129/2000\n",
      "3/3 [==============================] - 2s 521ms/step - loss: 0.4325 - categorical_accuracy: 0.7765\n",
      "Epoch 130/2000\n",
      "3/3 [==============================] - 2s 522ms/step - loss: 0.4229 - categorical_accuracy: 0.8000\n",
      "Epoch 131/2000\n",
      "3/3 [==============================] - 2s 547ms/step - loss: 0.4537 - categorical_accuracy: 0.7059\n",
      "Epoch 132/2000\n",
      "3/3 [==============================] - 2s 533ms/step - loss: 0.5327 - categorical_accuracy: 0.6353\n",
      "Epoch 133/2000\n",
      "3/3 [==============================] - 2s 547ms/step - loss: 0.5546 - categorical_accuracy: 0.6353\n",
      "Epoch 134/2000\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 0.7126 - categorical_accuracy: 0.6706\n",
      "Epoch 135/2000\n",
      "3/3 [==============================] - 2s 577ms/step - loss: 0.6771 - categorical_accuracy: 0.6588\n",
      "Epoch 136/2000\n",
      "3/3 [==============================] - 2s 574ms/step - loss: 0.5734 - categorical_accuracy: 0.6941\n",
      "Epoch 137/2000\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 0.6333 - categorical_accuracy: 0.6235\n",
      "Epoch 138/2000\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 0.5344 - categorical_accuracy: 0.6824\n",
      "Epoch 139/2000\n",
      "3/3 [==============================] - 2s 561ms/step - loss: 0.5626 - categorical_accuracy: 0.6471\n",
      "Epoch 140/2000\n",
      "3/3 [==============================] - 2s 536ms/step - loss: 0.5762 - categorical_accuracy: 0.6471\n",
      "Epoch 141/2000\n",
      "3/3 [==============================] - 2s 572ms/step - loss: 0.5230 - categorical_accuracy: 0.6706\n",
      "Epoch 142/2000\n",
      "3/3 [==============================] - 2s 575ms/step - loss: 0.4819 - categorical_accuracy: 0.6824\n",
      "Epoch 143/2000\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 0.4686 - categorical_accuracy: 0.6824\n",
      "Epoch 144/2000\n",
      "3/3 [==============================] - 2s 626ms/step - loss: 0.4511 - categorical_accuracy: 0.6824\n",
      "Epoch 145/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 651ms/step - loss: 0.4413 - categorical_accuracy: 0.6824\n",
      "Epoch 146/2000\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 0.4182 - categorical_accuracy: 0.7059\n",
      "Epoch 147/2000\n",
      "3/3 [==============================] - 2s 561ms/step - loss: 0.4074 - categorical_accuracy: 0.7765\n",
      "Epoch 148/2000\n",
      "3/3 [==============================] - 2s 569ms/step - loss: 0.3991 - categorical_accuracy: 0.7882\n",
      "Epoch 149/2000\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 0.3884 - categorical_accuracy: 0.8000\n",
      "Epoch 150/2000\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 0.3890 - categorical_accuracy: 0.7882\n",
      "Epoch 151/2000\n",
      "3/3 [==============================] - 2s 536ms/step - loss: 0.7315 - categorical_accuracy: 0.6824\n",
      "Epoch 152/2000\n",
      "3/3 [==============================] - 2s 536ms/step - loss: 0.4479 - categorical_accuracy: 0.7412\n",
      "Epoch 153/2000\n",
      "3/3 [==============================] - 2s 548ms/step - loss: 0.4726 - categorical_accuracy: 0.7176\n",
      "Epoch 154/2000\n",
      "3/3 [==============================] - 2s 579ms/step - loss: 0.4507 - categorical_accuracy: 0.7176\n",
      "Epoch 155/2000\n",
      "3/3 [==============================] - 2s 551ms/step - loss: 0.4572 - categorical_accuracy: 0.6824\n",
      "Epoch 156/2000\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 0.4365 - categorical_accuracy: 0.7647\n",
      "Epoch 157/2000\n",
      "3/3 [==============================] - 2s 617ms/step - loss: 0.4201 - categorical_accuracy: 0.7529\n",
      "Epoch 158/2000\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 0.4193 - categorical_accuracy: 0.7412\n",
      "Epoch 159/2000\n",
      "3/3 [==============================] - 2s 533ms/step - loss: 0.3990 - categorical_accuracy: 0.8000\n",
      "Epoch 160/2000\n",
      "3/3 [==============================] - 2s 538ms/step - loss: 0.3962 - categorical_accuracy: 0.8235\n",
      "Epoch 161/2000\n",
      "3/3 [==============================] - 2s 538ms/step - loss: 0.3756 - categorical_accuracy: 0.8118\n",
      "Epoch 162/2000\n",
      "3/3 [==============================] - 2s 585ms/step - loss: 0.3601 - categorical_accuracy: 0.8235\n",
      "Epoch 163/2000\n",
      "3/3 [==============================] - 2s 562ms/step - loss: 0.3577 - categorical_accuracy: 0.8118\n",
      "Epoch 164/2000\n",
      "3/3 [==============================] - 2s 560ms/step - loss: 0.5268 - categorical_accuracy: 0.7176\n",
      "Epoch 165/2000\n",
      "3/3 [==============================] - 2s 647ms/step - loss: 0.6339 - categorical_accuracy: 0.6235\n",
      "Epoch 166/2000\n",
      "3/3 [==============================] - 2s 587ms/step - loss: 0.4895 - categorical_accuracy: 0.6824\n",
      "Epoch 167/2000\n",
      "3/3 [==============================] - 2s 577ms/step - loss: 0.4543 - categorical_accuracy: 0.6824\n",
      "Epoch 168/2000\n",
      "3/3 [==============================] - 2s 565ms/step - loss: 0.4462 - categorical_accuracy: 0.6941\n",
      "Epoch 169/2000\n",
      "3/3 [==============================] - 2s 560ms/step - loss: 0.4588 - categorical_accuracy: 0.8000\n",
      "Epoch 170/2000\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 0.4593 - categorical_accuracy: 0.8000\n",
      "Epoch 171/2000\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 0.4357 - categorical_accuracy: 0.8000\n",
      "Epoch 172/2000\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 0.4376 - categorical_accuracy: 0.6824\n",
      "Epoch 173/2000\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 0.4495 - categorical_accuracy: 0.6824\n",
      "Epoch 174/2000\n",
      "3/3 [==============================] - 2s 638ms/step - loss: 0.4369 - categorical_accuracy: 0.6824\n",
      "Epoch 175/2000\n",
      "3/3 [==============================] - 2s 552ms/step - loss: 0.4107 - categorical_accuracy: 0.8353\n",
      "Epoch 176/2000\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 0.3967 - categorical_accuracy: 0.8118\n",
      "Epoch 177/2000\n",
      "3/3 [==============================] - 2s 567ms/step - loss: 0.3743 - categorical_accuracy: 0.8471\n",
      "Epoch 178/2000\n",
      "3/3 [==============================] - 2s 704ms/step - loss: 0.3612 - categorical_accuracy: 0.8353\n",
      "Epoch 179/2000\n",
      "3/3 [==============================] - 2s 624ms/step - loss: 0.3542 - categorical_accuracy: 0.8588\n",
      "Epoch 180/2000\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 0.3495 - categorical_accuracy: 0.8235\n",
      "Epoch 181/2000\n",
      "3/3 [==============================] - 2s 526ms/step - loss: 0.4259 - categorical_accuracy: 0.7412\n",
      "Epoch 182/2000\n",
      "3/3 [==============================] - 2s 526ms/step - loss: 0.4388 - categorical_accuracy: 0.7765\n",
      "Epoch 183/2000\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 0.3600 - categorical_accuracy: 0.7882\n",
      "Epoch 184/2000\n",
      "3/3 [==============================] - 2s 583ms/step - loss: 0.3145 - categorical_accuracy: 0.8824\n",
      "Epoch 185/2000\n",
      "3/3 [==============================] - 2s 527ms/step - loss: 0.4229 - categorical_accuracy: 0.7529\n",
      "Epoch 186/2000\n",
      "3/3 [==============================] - 2s 575ms/step - loss: 0.4037 - categorical_accuracy: 0.7765\n",
      "Epoch 187/2000\n",
      "3/3 [==============================] - 2s 552ms/step - loss: 0.3347 - categorical_accuracy: 0.8588\n",
      "Epoch 188/2000\n",
      "3/3 [==============================] - 2s 638ms/step - loss: 0.3193 - categorical_accuracy: 0.9059\n",
      "Epoch 189/2000\n",
      "3/3 [==============================] - 2s 577ms/step - loss: 0.3492 - categorical_accuracy: 0.8471\n",
      "Epoch 190/2000\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 0.4058 - categorical_accuracy: 0.7412\n",
      "Epoch 191/2000\n",
      "3/3 [==============================] - 2s 569ms/step - loss: 0.3770 - categorical_accuracy: 0.8118\n",
      "Epoch 192/2000\n",
      "3/3 [==============================] - 2s 521ms/step - loss: 0.3571 - categorical_accuracy: 0.8588\n",
      "Epoch 193/2000\n",
      "3/3 [==============================] - 2s 621ms/step - loss: 0.3091 - categorical_accuracy: 0.8471\n",
      "Epoch 194/2000\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 0.3149 - categorical_accuracy: 0.9176\n",
      "Epoch 195/2000\n",
      "3/3 [==============================] - 2s 575ms/step - loss: 0.3318 - categorical_accuracy: 0.8353\n",
      "Epoch 196/2000\n",
      "3/3 [==============================] - 2s 539ms/step - loss: 0.2768 - categorical_accuracy: 0.9294\n",
      "Epoch 197/2000\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 0.2657 - categorical_accuracy: 0.8824\n",
      "Epoch 198/2000\n",
      "3/3 [==============================] - 2s 627ms/step - loss: 0.2977 - categorical_accuracy: 0.8706\n",
      "Epoch 199/2000\n",
      "3/3 [==============================] - 2s 592ms/step - loss: 0.2783 - categorical_accuracy: 0.8824\n",
      "Epoch 200/2000\n",
      "3/3 [==============================] - 2s 583ms/step - loss: 0.2550 - categorical_accuracy: 0.8941\n",
      "Epoch 201/2000\n",
      "3/3 [==============================] - 2s 554ms/step - loss: 0.2314 - categorical_accuracy: 0.9294\n",
      "Epoch 202/2000\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 0.3526 - categorical_accuracy: 0.8353\n",
      "Epoch 203/2000\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 0.3215 - categorical_accuracy: 0.8941\n",
      "Epoch 204/2000\n",
      "3/3 [==============================] - 2s 587ms/step - loss: 0.3946 - categorical_accuracy: 0.7765\n",
      "Epoch 205/2000\n",
      "3/3 [==============================] - 2s 569ms/step - loss: 0.3815 - categorical_accuracy: 0.8471\n",
      "Epoch 206/2000\n",
      "3/3 [==============================] - 2s 617ms/step - loss: 0.5246 - categorical_accuracy: 0.6824\n",
      "Epoch 207/2000\n",
      "3/3 [==============================] - 2s 648ms/step - loss: 0.3300 - categorical_accuracy: 0.8588\n",
      "Epoch 208/2000\n",
      "3/3 [==============================] - 2s 642ms/step - loss: 0.3435 - categorical_accuracy: 0.8353\n",
      "Epoch 209/2000\n",
      "3/3 [==============================] - 2s 623ms/step - loss: 0.3240 - categorical_accuracy: 0.8471\n",
      "Epoch 210/2000\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 0.3056 - categorical_accuracy: 0.8588\n",
      "Epoch 211/2000\n",
      "3/3 [==============================] - 2s 549ms/step - loss: 0.2949 - categorical_accuracy: 0.8824\n",
      "Epoch 212/2000\n",
      "3/3 [==============================] - 2s 636ms/step - loss: 0.2505 - categorical_accuracy: 0.9059\n",
      "Epoch 213/2000\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 0.2476 - categorical_accuracy: 0.9059\n",
      "Epoch 214/2000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.2356 - categorical_accuracy: 0.9219"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13180/647883075.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtb_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=2000, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7dfdd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 30, 64)            442112    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596,675\n",
      "Trainable params: 596,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc537161",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2efb978",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bcfa293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8440920e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e8f4213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thanks'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06e4a506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iloveyou'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a90514",
   "metadata": {},
   "source": [
    "# Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7528c7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18560/1434355117.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'action.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('action.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6418393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b81eed4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model1 = keras.models.load_model(\"action.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d52fda",
   "metadata": {},
   "source": [
    "# Evaluation using Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31bb6dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04b9994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16afbdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51c8dfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3, 1],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[1, 0],\n",
       "        [1, 3]]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad6ade1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ac16ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 0, 2, 2]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b9792fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 0, 2, 2]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb10b9b",
   "metadata": {},
   "source": [
    "# Test in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e72143eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence=[]\n",
    "sentence=[]\n",
    "threshold=0.4\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detections\n",
    "        image,results = mediapipe_detection(frame,holistic)\n",
    "        \n",
    "        #draw landmarks\n",
    "#         draw_landmarks(image,results)\n",
    "        draw_styled_landmarks(image,results)\n",
    "        \n",
    "        #prediction login\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        if len(sequence)==30:\n",
    "            res = model1.predict(np.expand_dims(sequence,axis=0))[0]\n",
    "            \n",
    "        #viz logic\n",
    "        if res[np.argmax(res)]>threshold:\n",
    "            if len(sentence)>0:\n",
    "                if actions[np.argmax(res)] != sentence[-1]:\n",
    "                    sentence.append(actions[np.argmax(res)])\n",
    "            else:\n",
    "                sentence.append(actions[np.argmax(res)])\n",
    "                    \n",
    "        if len(sentence)>5:\n",
    "            sentence = sentence[-5:]\n",
    "        \n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "            \n",
    "        #show to screen\n",
    "        cv2.imshow('OpenCV Feed',image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66823701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d2e04c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa76b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af634a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64790e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.5\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "#         print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model1.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "#             print(actions[np.argmax(res)])\n",
    "            predictions.append(np.argmax(res))\n",
    "            \n",
    "            \n",
    "        #3. Viz logic\n",
    "            if np.unique(predictions[-10:])[0]==np.argmax(res): \n",
    "                if res[np.argmax(res)] > threshold: \n",
    "                    \n",
    "                    if len(sentence) > 0: \n",
    "                        if actions[np.argmax(res)] != sentence[-1]:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "                    else:\n",
    "                        sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "            if len(sentence) > 5: \n",
    "                sentence = sentence[-5:]\n",
    "\n",
    "            # Viz probabilities\n",
    "            image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa276b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
